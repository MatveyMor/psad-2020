{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from pymystem3 import Mystem\n",
    "from itertools import chain\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from permute.core import two_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очистим данные и лемматизируем слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(filename):\n",
    "    with open(filename) as fp:\n",
    "        lines = [re.sub(\"[^а-я\\s]\", \"\", line.lower()) for line in fp.readlines()]\n",
    "    lines = [re.sub(\"\\s+\", \" \", line).strip() for line in lines]\n",
    "    stemmer = Mystem()\n",
    "    words = chain.from_iterable([\n",
    "        [\n",
    "            word for word in stemmer.lemmatize(line) if re.match('[а-я]+', word)\n",
    "        ] \n",
    "        for line in tqdm(lines)\n",
    "    ]\n",
    "    )\n",
    "    words = list(words)\n",
    "    shuffle(words)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18130/18130 [00:18<00:00, 1002.66it/s]\n",
      "100%|██████████| 1997/1997 [00:03<00:00, 610.42it/s]\n"
     ]
    }
   ],
   "source": [
    "tolstoy_words = get_words('tolstoj_lew_nikolaewich-text_0080.txt')\n",
    "news_words = get_words('ru.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in Anna Karenina: 268392\n",
      "Number of words in news corpus: 39020\n",
      "\n",
      "Number of unique words in Anna Karenina: 12396\n",
      "Number of unique words in news corpus: 6359\n"
     ]
    }
   ],
   "source": [
    "tolstoy_count = Counter(tolstoy_words)\n",
    "news_count = Counter(news_words)\n",
    "\n",
    "print(f\"Number of words in Anna Karenina: {len(tolstoy_words)}\")\n",
    "print(f\"Number of words in news corpus: {len(news_words)}\" + \"\\n\")\n",
    "print(f\"Number of unique words in Anna Karenina: {len(tolstoy_count)}\")\n",
    "print(f\"Number of unique words in news corpus: {len(news_count)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('и', 12905),\n",
       " ('он', 9298),\n",
       " ('не', 6534),\n",
       " ('что', 6063),\n",
       " ('она', 6001),\n",
       " ('в', 5715),\n",
       " ('быть', 5282),\n",
       " ('я', 4491),\n",
       " ('на', 3594),\n",
       " ('с', 3328)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tolstoy_count.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('в', 1964),\n",
       " ('и', 1013),\n",
       " ('что', 759),\n",
       " ('на', 707),\n",
       " ('быть', 614),\n",
       " ('он', 428),\n",
       " ('с', 401),\n",
       " ('который', 378),\n",
       " ('не', 371),\n",
       " ('как', 343)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_count.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLE of Zipf's law distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zipf's law:  $$\\mathbb{P}\\left[rank(x)=k\\right|a] = \\frac{c}{k^a}$$\n",
    "where $x$ represents a word, $N$ - total number of words, $rank(x)$ - rank of the word determined by sample.\n",
    "\n",
    "C is determined by normalizing conditions:\n",
    "$$c = \\frac{1}{\\sum\\limits_{k=1}^{N}\\frac{1}{k^a}}$$\n",
    "Likelihood for a sample $x = (x_1, x_2, ..., x_n)$ of size n:\n",
    "$$L = c^n\\left(\\prod\\limits_{i=1}^{n}\\frac{1}{(rank(x_i))^a}\\right)$$\n",
    "$$\\ln(L) = -n\\ln\\left(\\sum\\limits_{k=1}^{N}\\frac{1}{k^a}\\right) - a\\sum\\limits_{i=1}^{n}\\ln(rank(x_i))$$\n",
    "\n",
    "$$\\frac{1}{n}\\ln(L) = -\\ln\\left(\\sum\\limits_{k=1}^{N}\\frac{1}{k^a}\\right) - a\\frac{1}{n}\\sum\\limits_{i=1}^{n}\\ln(rank(x_i))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logL(a, sample):\n",
    "    N = max(sample)\n",
    "    c = 1.0/np.sum([(1.0/k)**a for k in range(1, N+1)])\n",
    "    lnL = np.log(c) - a*np.mean(np.log(sample))\n",
    "    return lnL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximizing loglikelihood is equivalent to minimizing -loglikelihood\n",
    "def find_a(sample):\n",
    "    return minimize(lambda a: -logL(a, sample), x0=[0.9]).x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Переведем выборку из слов в ранги \n",
    "tolstoy_rank = {w:i+1 for i, (w, c) in enumerate(tolstoy_count.most_common())}\n",
    "news_rank = {w:i+1 for i, (w, c) in enumerate(news_count.most_common())}\n",
    "tolstoy_s = [tolstoy_rank[w] for w in tolstoy_words]\n",
    "news_s = [news_rank[w] for w in news_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tolstoy_a = find_a(tolstoy_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_a = find_a(news_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter 'a' for Anna Karenina:1.003967666194625\n",
      "Parameter 'a' for news corpus:0.8738136100564119\n",
      "\n",
      "Parameter 'c' for Anna Karenina:0.10174369488436825\n",
      "Parameter 'c' for news corpus:0.06034151087263045\n"
     ]
    }
   ],
   "source": [
    "print(f\"Parameter 'a' for Anna Karenina:{tolstoy_a}\")\n",
    "print(f\"Parameter 'a' for news corpus:{news_a}\" + \"\\n\")\n",
    "\n",
    "tolstoy_c = 1.0/np.sum([(1.0/k)**tolstoy_a for k in range(1, len(tolstoy_rank)+1)])\n",
    "news_c = 1.0/np.sum([(1.0/k)**news_a for k in range(1, len(news_rank)+1)])\n",
    "\n",
    "print(f\"Parameter 'c' for Anna Karenina:{tolstoy_c}\")\n",
    "print(f\"Parameter 'c' for news corpus:{news_c}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chi2 test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, дейстительно ли мы вероятности подчиняются закону Ципфа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Power_divergenceResult(statistic=0.11684582924175284, pvalue=1.0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observed frequencies\n",
    "tolstoy_obs_f = np.array([tolstoy_count[w] for w in tolstoy_rank]) \n",
    "tolstoy_obs_f = tolstoy_obs_f/np.sum(tolstoy_obs_f)\n",
    "# Calculated Zipf's law frequencies\n",
    "tolstoy_exp_f = [tolstoy_c/k**tolstoy_a for k in range(1, len(tolstoy_rank)+1)] \n",
    "st.chisquare(f_obs=tolstoy_obs_f, f_exp=tolstoy_exp_f, ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Power_divergenceResult(statistic=2.0895418051454455, pvalue=1.0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_obs_f = np.array([tolstoy_count[w] for w in news_rank])\n",
    "news_obs_f = news_obs_f/np.sum(news_obs_f)\n",
    "news_exp_f = [tolstoy_c/k**news_a for k in range(1, len(news_rank)+1)]\n",
    "st.chisquare(f_obs=news_obs_f, f_exp=news_exp_f, ddof=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, не можем отвергнуть нулевую гипотезу о том, что распределение подчинено закону Ципфа (pvalue=1.0).\n",
    "\n",
    "Будем считать предположение верным."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test for equality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получим доверительные интервалы для нашей оценки $a_{MLE}$ для обоих выборок с помощью бутстрепа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arch.bootstrap import IIDBootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00292161]\n",
      " [1.00506477]]\n",
      "CPU times: user 13min 44s, sys: 10.2 s, total: 13min 54s\n",
      "Wall time: 14min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bs = IIDBootstrap(np.array(tolstoy_s))\n",
    "print(bs.conf_int(find_a, 1000, size=0.95, method='basic'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.87006576]\n",
      " [0.87739855]]\n",
      "CPU times: user 4min 10s, sys: 4.52 s, total: 4min 14s\n",
      "Wall time: 4min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bs = IIDBootstrap(np.array(news_s))\n",
    "print(bs.conf_int(find_a, 1000, size=0.95, method='basic'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, 95% доверительные интервалы оценок не пересекаются, и мы можем отвергнуть гипотезу о равенстве параметров распределений."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
